# 数据搬运 {#chap:data-transportation}

美团使用的大数据工具有很多，最常用的 Hive、Spark、Kylin、Impala、Presto 等，详见 <https://tech.meituan.com/2018/08/02/mt-r-practice.html>。下面主要介绍如何在 R 中连接 MySQL、Presto 和 Spark。

Presto 的 R 接口 <https://github.com/prestodb/RPresto>，

朱俊晖收集的 Spark 资源列表 <https://github.com/harryprince/awesome-sparklyr>，推荐使用 sparklyr <https://github.com/sparklyr/sparklyr> 连接 Spark

Spark 性能优化，参考三篇博文

- [Spark在美团的实践](https://tech.meituan.com/2016/03/31/spark-in-meituan.html)
- [Spark性能优化指南——基础篇](https://tech.meituan.com/2016/04/29/spark-tuning-basic.html)
- [Spark性能优化指南——高级篇](https://tech.meituan.com/2016/05/12/spark-tuning-pro.html)

Mastering Spark with R <https://therinspark.com/>

```{r,eval=FALSE}
install.packages('sparklyr')
library(sparklyr)
spark_install(version = '3.0') # 连同 hadoop 2.7 一起安装

install.packages('RPresto')
```

## 数据库与 R 语言 {#sec:database-with-r}

MySQL 为例介绍 odbc 的连接和使用，详见 [从 R 连接 MySQL](https://cosx.org/2020/06/connect-mysql-from-r/)

```{sql,eval=F}
-- !preview conn=DBI::dbConnect(odbc::odbc(),  driver = "MariaDB", database = "demo", uid = "root", pwd = "cloud", host = "localhost", port = 3306)

SELECT * FROM mtcars
LIMIT 10
```

我的系统已经安装了多款数据库的 ODBC 驱动

```bash
dnf install -y unixODBC unixODBC-devel mariadb mariadb-server mariadb-devel mariadb-connector-odbc
```

```r
odbc::odbcListDrivers()
```
```
# Driver from the mariadb-connector-odbc package
# Setup from the unixODBC package
[MariaDB]
Description     = ODBC for MariaDB
Driver          = /usr/lib/libmaodbc.so
Driver64        = /usr/lib64/libmaodbc.so
FileUsage       = 1
```



## 批量读取 csv 文件 {#sec:batch-xlsx-import}

iris 拆分成 csv xlsx 文件，分别用 fread/openxlsx 批量读取、导出

按照 Species 分组拆成单独的 csv 文件，各个文件的文件名用鸢尾花的类别名表示

```{r,eval=FALSE}
# 批量分组导出
library(data.table)
as.data.table(iris)[, fwrite(.SD, paste0("data/user_", unique(Species), ".csv")), by = Species, .SDcols = colnames(iris)]
```


```{r,eval=FALSE}
library(data.table)

merged_df <- do.call('rbind', lapply(list.files(pattern = "*.csv", path = "data/"), fread ) )
```


```{r,eval=FALSE}
xdf$date <- as.Date(xdf$date)
xdf$ts <- as.POSIXct(as.numeric(xdf$ts), origin = "1978-01-01")
split(xdf[order(xdf$ts), ], interaction(xdf$study, xdf$port)) %>%
  lapply(function(.x) {
    .x[nrow(.x), ]
  }) %>%
  unname() %>%
  Filter(function(.x) {
    nrow(.x) > 0
  }, .) %>%
  do.call(rbind.data.frame, .)

library(dplyr)
xdf %>%
  mutate(
    date = as.Date(date),
    ts = anytime::anytime(as.numeric(ts))
  ) %>%
  arrange(ts) %>%
  group_by(study, port) %>%
  slice(n()) %>%
  ungroup()
```


```{r}
library(tibble)
library(magrittr)

mtcars <- tibble(mtcars)

mtcars %>% 
  print(n = 16, width = 69)
```


```{r}
mtcars %>% 
  print(., n = nrow(.)/4)
```

## 批量导出 xlsx 文件 {#sec:batch-xlsx-export}


将 R 环境中的数据集导出为 xlsx 表格

```{r,eval=FALSE}
## 加载 openxlsx 包
library(openxlsx)
## 创建空白的工作薄，标题为鸢尾花数据集
wb <- createWorkbook(title = "鸢尾花数据集")
## 添加 sheet 页
addWorksheet(wb, sheetName = "iris")
# 将数据写进 sheet 页
writeData(wb, sheet = "iris", x = iris, colNames = TRUE)
# 导出数据到本地
saveWorkbook(wb, file = "iris.xlsx", overwrite = TRUE)
```


```{r,eval=FALSE}
library(openxlsx)
xlsxFile <- system.file("extdata", "readTest.xlsx", package = "openxlsx")
# 导入
dat = read.xlsx(xlsxFile = xlsxFile)
# 导出
write.xlsx(dat, xlsxfile)
```

